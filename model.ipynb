{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Objective\n",
    "\n",
    "Develop a minimum viable model that can predict which direction a stock will go\n",
    "\n",
    "## The Data\n",
    "\n",
    "### Input Variables\n",
    "\n",
    "1. Sentiment\n",
    "    - Bullish, Bearish, Total_compound\n",
    "2. Financial\n",
    "3. Technical\n",
    "\n",
    "### Target Variable\n",
    "\n",
    "1. 1-day price direction\n",
    "2. 2-day price direction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import requests\n",
    "# import json\n",
    "# import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Import data and convert date column to datetime datatype\n",
    "data = pd.read_csv('historic_sentiment_analysis.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unnecessary Columns\n",
    "\n",
    "Let's dig into dividend data. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data[['divYield', 'divAmount', 'divDate', 'dividendYield', 'dividendAmount', 'dividendDate']].head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   divYield  divAmount  divDate  dividendYield  dividendAmount dividendDate\n",
       "0      0.00       0.00      NaN           0.00            0.00             \n",
       "1      0.00       0.00      NaN           0.00            0.00             \n",
       "2      0.00       0.00      NaN           0.00            0.00             \n",
       "3      0.70       0.88  00:00.0           0.70            0.88      00:00.0\n",
       "4      0.00       0.00      NaN           0.00            0.00             \n",
       "5      0.00       0.00      NaN           0.00            0.00             \n",
       "6      0.00       0.00      NaN           0.00            0.00             \n",
       "7      0.00       0.00      NaN           0.00            0.00             \n",
       "8      0.71       0.88  00:00.0           0.71            0.88      00:00.0\n",
       "9      0.09       0.64  00:00.0           0.09            0.64      00:00.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>divYield</th>\n",
       "      <th>divAmount</th>\n",
       "      <th>divDate</th>\n",
       "      <th>dividendYield</th>\n",
       "      <th>dividendAmount</th>\n",
       "      <th>dividendDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.88</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.88</td>\n",
       "      <td>00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.88</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.88</td>\n",
       "      <td>00:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>00:00.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most of the values are null/zero values because most stocks don't provide dividends.\n",
    "\n",
    "Also, there are duplicate columns (ex: divAmount & dividendAmount).\n",
    "\n",
    "For simplicity, let's consolidate them columns into one as follows:\n",
    "1. Remove the dividendDate/divDate columns. Keeping this would be redundant\n",
    "2. Remove divYield column, it contains the same information as divAmount\n",
    "3. The information from the 6 columns is contained in divAmount:\n",
    "    - Whether the stock pays a dividend or not\n",
    "    - How much is paid per stock owned"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data.drop(['divYield', 'divDate', 'dividendYield', 'dividendAmount', 'dividendDate', 'dividendPayDate'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Several columns are either identifiers, duplicates or empty, we don't need them for this project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data.drop(['cusip',\n",
    "           'assetType',\n",
    "           'description',\n",
    "           'assetMainType',\n",
    "           'symbol',\n",
    "           'securityStatus',\n",
    "           'symbol.1',\n",
    "           'bidTick',\n",
    "           'exchangeName',\n",
    "           'peRatio.1'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Categorical columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data.select_dtypes(include='object')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    stock bidId askId lastId exchange\n",
       "0    CLOV     P     P      P        q\n",
       "1    CLNE     Q     P      P        q\n",
       "2    TLRY     P     P      P        q\n",
       "3    AAPL     P     P      D        q\n",
       "4    WKHS     P     P      D        q\n",
       "..    ...   ...   ...    ...      ...\n",
       "620  UPST     Q     P      P        q\n",
       "621  SOFI     P     P      P        q\n",
       "622    MU     P     P      P        q\n",
       "623  AMZN     P     P      D        q\n",
       "624   AMD     P     P      D        q\n",
       "\n",
       "[625 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>bidId</th>\n",
       "      <th>askId</th>\n",
       "      <th>lastId</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLOV</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLNE</td>\n",
       "      <td>Q</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLRY</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WKHS</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>UPST</td>\n",
       "      <td>Q</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>SOFI</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>MU</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>AMD</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>D</td>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(data['bidId'].nunique())\n",
    "print(data['askId'].nunique())\n",
    "print(data['lastId'].nunique())\n",
    "print(data['exchange'].nunique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n",
      "13\n",
      "14\n",
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "exchange column has only 1 unique value, which would likely not add predictability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data.drop(['exchange'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boolean Values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data.select_dtypes(include='boolean')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     marginable  shortable  delayed  realtimeEntitled\n",
       "0          True       True     True             False\n",
       "1          True       True     True             False\n",
       "2          True       True     True             False\n",
       "3          True       True     True             False\n",
       "4          True       True     True             False\n",
       "..          ...        ...      ...               ...\n",
       "620        True       True     True             False\n",
       "621        True       True     True             False\n",
       "622        True       True     True             False\n",
       "623        True       True     True             False\n",
       "624        True       True     True             False\n",
       "\n",
       "[625 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marginable</th>\n",
       "      <th>shortable</th>\n",
       "      <th>delayed</th>\n",
       "      <th>realtimeEntitled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(data['marginable'].nunique())\n",
    "print(data['shortable'].nunique())\n",
    "print(data['delayed'].nunique())\n",
    "print(data['realtimeEntitled'].nunique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two of these columns provide no valuable information"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.drop(['delayed', 'realtimeEntitled'], axis=1, inplace=True, )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#data = data.transpose(copy=True).drop_duplicates().transpose(copy=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Null Values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.isna().sum().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're good to go"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Columns with minimal unique values\n",
    "\n",
    "Variables with a single value in the column will not likely provide any predictability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list(data.columns)\n",
    "\n",
    "for column in list(data.columns):\n",
    "    if data[column].nunique() <= 1:\n",
    "        data.drop(column, axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bring in price data with TDAmeritrade API"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Date range of our dataset\n",
    "print(data['date'].min().date())\n",
    "print(data['date'].max().date())\n",
    "print(data['date'].max().date() - data['date'].min().date())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the date range of our dataset, our API call should generate about 2 months of price history"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Note: The API does not produce data on the weekends\n",
    "n_period = 3\n",
    "api_key = \"***REMOVED***\"\n",
    "price_data = pd.DataFrame()\n",
    "\n",
    "for stock in list(data['stock'].unique()):\n",
    "    symbol = stock\n",
    "    url = f'https://api.tdameritrade.com/v1/marketdata/{symbol}/pricehistory?apikey={api_key}&periodType=month&period={n_period}&frequencyType=daily&frequency=1'\n",
    "    raw_data = requests.get(url).json()\n",
    "    # raw_data = requests.get(url)\n",
    "    # print(raw_data.status_code)\n",
    "    # print(raw_data)\n",
    "    raw_data = pd.json_normalize(raw_data, record_path=['candles'])\n",
    "    raw_data.rename(columns = {'datetime': 'date'}, inplace=True)\n",
    "    raw_data['date'] = pd.to_datetime(raw_data['date'], unit='ms')\n",
    "    raw_data['date'] = [raw_data['date'][i].date() for i in range(len(raw_data['date']))]\n",
    "    raw_data['stock'] = [stock for x in range(len(raw_data))]\n",
    "\n",
    "    # Calc returns\n",
    "    raw_data['1d-logreturn'] = np.log(raw_data['close'] / raw_data['close'].shift(1))\n",
    "    raw_data['2d-logreturn'] = np.log(raw_data['close'] / raw_data['close'].shift(2))\n",
    "    raw_data['5d-logreturn'] = np.log(raw_data['close'] / raw_data['close'].shift(5))\n",
    "\n",
    "    # Determine direction of return\n",
    "    raw_data['1d-direction'] = [1 if x > 0 else -1 if x < 0 else 0 for x in raw_data['1d-logreturn']]\n",
    "    raw_data['2d-direction'] = [1 if x > 0 else -1 if x < 0 else 0 for x in raw_data['2d-logreturn']]\n",
    "    raw_data['5d-direction'] = [1 if x > 0 else -1 if x < 0 else 0 for x in raw_data['5d-logreturn']]\n",
    "\n",
    "    # Concat dataframes\n",
    "    price_data = pd.concat([price_data, raw_data], ignore_index=True)\n",
    "    price_data = price_data[['date',\n",
    "                             'stock',\n",
    "                             'close',\n",
    "                             '1d-logreturn',\n",
    "                             '1d-direction',\n",
    "                             '2d-logreturn',\n",
    "                             '2d-direction',\n",
    "                             '5d-logreturn',\n",
    "                             '5d-direction']]\n",
    "\n",
    "# First n values in direction columns should be NaN\n",
    "price_data['1d-direction'][0] = np.nan\n",
    "price_data['2d-direction'][0: 2] = [np.nan for x in price_data['2d-direction'][0: 2]]\n",
    "price_data['5d-direction'][0: 5] = [np.nan for x in price_data['5d-direction'][0: 5]]\n",
    "\n",
    "price_data['1d-logreturn'] = price_data['1d-logreturn'].shift(1)\n",
    "price_data['1d-direction'] = price_data['1d-direction'].shift(1)\n",
    "\n",
    "price_data['2d-logreturn'] = price_data['2d-logreturn'].shift(1)\n",
    "price_data['2d-direction'] = price_data['2d-direction'].shift(1)\n",
    "\n",
    "price_data['5d-logreturn'] = price_data['5d-logreturn'].shift(1)\n",
    "price_data['5d-direction'] = price_data['5d-direction'].shift(1)\n",
    "\n",
    "price_data.dropna(inplace=True)\n",
    "price_data.reset_index(inplace=True)\n",
    "price_data.drop('index', axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filter out dates to match those of the 'data' dataframe\n",
    "filter_ = (price_data['date'] >= data['date'].min().date()) & (price_data['date'] <= data['date'].max().date())\n",
    "\n",
    "price_data = price_data[filter_]\n",
    "price_data.reset_index(inplace=True)\n",
    "price_data.drop('index', axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Instantiate combined dataframe\n",
    "column_list = list(price_data.columns) + list(data.columns)\n",
    "combined_df = pd.DataFrame(columns=column_list)\n",
    "\n",
    "# Iterate through both dataframes to match date and stock and append matching rows into combined_df\n",
    "for ind in price_data.index:\n",
    "    for indx in data.index:\n",
    "        if price_data['date'][ind] == data['date'][indx] and price_data['stock'][ind] == data['stock'][indx]:\n",
    "            series_list = [\n",
    "                pd.to_datetime(price_data['date'][ind]),\n",
    "                price_data['stock'][ind],\n",
    "                price_data['close'][ind],\n",
    "                price_data['1d-logreturn'][ind],\n",
    "                price_data['1d-direction'][ind],\n",
    "                price_data['2d-logreturn'][ind],\n",
    "                price_data['2d-direction'][ind],\n",
    "                price_data['5d-logreturn'][ind],\n",
    "                price_data['5d-direction'][ind]] + list(data.iloc[indx])\n",
    "            combined_df = combined_df.append(pd.Series(\n",
    "                    series_list,\n",
    "                    index=column_list\n",
    "                ), ignore_index=True)\n",
    "\n",
    "# We don't need duplicate 'date' and 'stock' columns anymore\n",
    "combined_df = combined_df.iloc[:, 2:]\n",
    "combined_df.sort_values(by='date', ignore_index=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Officially ready for modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Minimal Viable Product"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Features and Target Variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert target to numeric datatype\n",
    "int_list = ['bidSize', 'askSize', 'lastSize', 'totalVolume', 'regularMarketLastSize']\n",
    "\n",
    "for int_ in int_list:\n",
    "    combined_df[int_] = pd.to_numeric(combined_df[int_])\n",
    "\n",
    "combined_df['1d-direction'] = pd.to_numeric(combined_df['1d-direction'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = combined_df.loc[:, 'Bearish':].drop('date', axis=1)\n",
    "y = combined_df['1d-direction']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode Categorical Variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categoricals = list(X.select_dtypes('object').columns)\n",
    "numericals = list(X.select_dtypes(['int64', 'float64']).columns)\n",
    "\n",
    "def encode_cats(categoricals, numericals):\n",
    "    \"\"\"\n",
    "    Takes in a list of categorical columns and a list of numerical columns and returns the dataframe with encoded variables\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "    cat_matrix = ohe.fit_transform(X.loc[:, categoricals])\n",
    "    X_ohe = pd.DataFrame(cat_matrix,\n",
    "                         columns=ohe.get_feature_names(categoricals), #create meaningful column names\n",
    "                         index=X.index) #keep the same index values\n",
    "    \n",
    "    return pd.concat([X.loc[:, numericals], X_ohe], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = encode_cats(categoricals, numericals)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import auc, roc_auc_score, plot_roc_curve, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, PrecisionRecallDisplay, plot_confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=42) #hold out 20% of the data for final testing\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_scores = cross_val_score(knn, X_scaled, y, cv=5)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr_scores = cross_val_score(lr, X_scaled, y, cv = 5)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_scores = cross_val_score(rf, X_scaled, y, cv=5)\n",
    "\n",
    "gbm = xgb.XGBClassifier()\n",
    "gbm_scores = cross_val_score(gbm, X_scaled, y, cv=5)\n",
    "\n",
    "print(f\"KNN mean scores: {np.mean(knn_scores):.4}\")\n",
    "\n",
    "print(f\"Logistic Regression mean scores: {np.mean(lr_scores):.4}\")\n",
    "\n",
    "print(f\"Random Forest mean scores: {np.mean(rf_scores):.4}\")\n",
    "\n",
    "print(f\"XGBoost mean scores: {np.mean(gbm_scores):.4}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Precicion score\n",
    "rf.fit(X_scaled, y)\n",
    "print(f\"Precision Score: {precision_score(y_test, rf.predict(X_test_scaled), average='weighted'):.4f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Recall Score\n",
    "print(f\"Recall Score: {recall_score(y_test, rf.predict(X_test_scaled), average='weighted'):.4f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(rf, X_test, y_test)\n",
    "plt.grid(b=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimize Precision\n",
    "\n",
    "We want to be as accurate as possible to ensure profitability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove the noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}